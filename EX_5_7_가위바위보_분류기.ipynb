{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EX 5-7. 가위바위보 분류기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "11WbEX3IuMT7szb3Y6yD1QV_VZ2o7KI3J",
      "authorship_tag": "ABX9TyPmJwEHjlKcj5BFy7o0EZMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aivrm/ai/blob/main/EX_5_7_%EA%B0%80%EC%9C%84%EB%B0%94%EC%9C%84%EB%B3%B4_%EB%B6%84%EB%A5%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5-7. 미니 프로젝트 : 가위바위보 분류기를 만들자\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SX9jpzBJtiiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q99OOAJUtZfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b263796-44ab-4aa7-a079-1dc9f8f915b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "1.21.6\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "아래의 사이트에서,  가위,바위,보 이미지를 각각 100개씩 캡쳐하여 zip화일로 받는다. (224x224 픽셀의 이미지임)\n",
        "\n",
        "Teachable Machine\n",
        "\n",
        "https://teachablemachine.withgoogle.com/\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "oe44rDL-t05-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "가위 는 scissor.zip\n",
        "\n",
        "바위 는 rock.zip\n",
        "\n",
        "보 는 paper.zip 로 이름을 바꾸고,\n",
        "\n",
        "각각의 zip화일에는 이미지 100개씩 들어있도록 한다.  (224x224 픽셀의 이미지들임)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1HFc9EfcszFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "~/aiffel/aiffel/rock_scissor_paper 디렉토리에,\n",
        "\n",
        "scissor, rock, paper 디렉토리를 만든다.\n",
        "\n",
        "해당 디렉토리에 맞는 zip화일을 넣고,\n",
        "\n",
        "unzip으로 압축을 푼다.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Snugq_kttGNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "\n",
        "print(\"PIL 라이브러리 import 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbsQPDP8t3KB",
        "outputId": "83f4c9ab-16de-4cec-ccf4-5f09f631ca58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIL 라이브러리 import 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "위에서 획득한 이미지는 224x224 픽셀인데,\n",
        "\n",
        "28x28 픽셀의 이미지로 리사이즈 한다.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "P7eFUdIptx8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 28x28 픽셀로 리사이즈\n",
        "def resize_images(img_path):\n",
        "    images = glob.glob(img_path + \"/*.jpg\")\n",
        "\n",
        "    print(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "    target_size = (28, 28)\n",
        "\n",
        "    for img in images:\n",
        "        old_img = Image.open(img)\n",
        "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
        "        new_img.save(img, \"JPEG\")\n",
        "\n",
        "    print(len(images), \" images resized.\")"
      ],
      "metadata": {
        "id": "-fZB1yKmzAFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import join\n",
        "DIR_img = '/content/drive/MyDrive/_aiffel/aiffel/rock_scissor_paper'"
      ],
      "metadata": {
        "id": "j6SgKAsNm4oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가위 이미지가 저장된 scissor 디렉토리 아래의 모든 jpg 파일을 28x28 픽셀로\n",
        "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
        "image_dir_path = join(DIR_img, 'scissor')\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"가위 이미지 resize 완료!\")"
      ],
      "metadata": {
        "id": "FJJYlUG21TSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e148404-ebce-4b65-c8dc-630f95460f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100  images to be resized.\n",
            "100  images resized.\n",
            "가위 이미지 resize 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 바위 이미지가 저장된 rock 디렉토리 아래의 모든 jpg 파일을 28x28 픽셀로\n",
        "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
        "image_dir_path = join(DIR_img, 'rock')\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"바위 이미지 resize 완료!\")"
      ],
      "metadata": {
        "id": "MjAsj_4R1Woh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa803538-136b-405f-ae35-77a8db66e70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100  images to be resized.\n",
            "100  images resized.\n",
            "바위 이미지 resize 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 보 이미지가 저장된 paper 디렉토리 아래의 모든 jpg 파일을 28x28 픽셀로\n",
        "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
        "image_dir_path = join(DIR_img, 'paper')\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"보 이미지 resize 완료!\")"
      ],
      "metadata": {
        "id": "7MXMfsH71Xjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e4b65d-4812-41c5-90ec-df18cfd50022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100  images to be resized.\n",
            "100  images resized.\n",
            "보 이미지 resize 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "scissor, rock, paper 디렉토리의 jpg 이미지들을, 편리하게 읽어들이는 함수\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vKrtFOuow5vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scissor, rock, paper 디렉토리의 jpg 이미지들을, 편리하게 읽어들이는 함수\n",
        "def load_data(img_path, number_of_data=300):    # 가위바위보 이미지 갯수 총합 300장\n",
        "\n",
        "    # 가위:0 | 바위:1 | 보:2\n",
        "    img_size = 28\n",
        "    color = 3\n",
        "\n",
        "    # 이미지 데이터와 라벨(가위:0 | 바위:1 | 보:2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
        "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
        "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
        "\n",
        "    idx = 0\n",
        "    for file in glob.iglob(img_path + '/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img    # 데이터 영역에 이미지 행력을 복사\n",
        "        labels[idx]=0   # 가위 : 0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=1   # 바위 : 1\n",
        "        idx=idx+1  \n",
        "    \n",
        "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=2   # 보 : 2\n",
        "        idx=idx+1\n",
        "        \n",
        "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
        "    return imgs, labels"
      ],
      "metadata": {
        "id": "1qRA-gMkxEoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "정규화\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lwqMKPvrxRho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(DIR_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz3oy2kD6cp7",
        "outputId": "a19f83b9-505c-4b24-b8fc-fba0c0d36019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/_aiffel/aiffel/rock_scissor_paper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
        "\n",
        "(x_train, y_train) = load_data(DIR_img)\n",
        "\n",
        "# 정규화\n",
        "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
        "\n",
        "print(\"x_train shape: {}\".format(x_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbS6PQDYxUxK",
        "outputId": "3d963a3f-ad46-4772-fa4a-da7ab1afb7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
            "x_train shape: (300, 28, 28, 3)\n",
            "y_train shape: (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "샘플로 하나 확인\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "n7JEnqXLxx27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[0])\n",
        "print('라벨: ', y_train[0])"
      ],
      "metadata": {
        "id": "0CTpAffax0SJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "416669d2-ab0c-4682-c184-26d0707a276c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "라벨:  0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "딥러닝 네트웍 설계\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0BZDK1n8yQZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# hyperpameters\n",
        "n_channel_1 = 16\n",
        "n_channel_2 = 64\n",
        "n_dense = 128\n",
        "\n",
        "n_train_epoch = 20\n",
        "\n",
        "# tensorflow.keras 의 Sequential API\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3))) # 입력 이미지의 형태\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))    # 입력 이미지가 다양할수록 더 많은 특징을 보자.\n",
        "model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(n_dense, activation='relu'))    # 분류기 알고리즘을 얼마나 복잡하게 할 것인가? (복잡한 문제일수록 이 수를 증가시킬 것)\n",
        "model.add(keras.layers.Dense(3, activation='softmax')) # 분류기의 최종 class 수 (여기서는 3개)\n",
        "\n",
        "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
        "\n",
        "# 모델 개요\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eO0s6gzIyWML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52af9896-da14-4254-e36d-6707a5efe731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model에 추가된 Layer 개수:  7\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 16)        448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        9280      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 215,043\n",
            "Trainable params: 215,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "딥러닝 네트웍 학습\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "102NA7LRyZnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape\n",
        "'''\n",
        "print(\"Before Reshape - x_train_norm shape : {}\".format(x_train_norm.shape))\n",
        "x_train_reshaped = x_train_norm.reshape( -1, 28, 28, 3) # 데이터 갯수에 -1을 쓰면, reshape시 자동계산됩니다.\n",
        "print(\"After Reshape - x_train_reshaped shape : {}\".format(x_train_reshaped.shape))\n",
        "'''"
      ],
      "metadata": {
        "id": "xeahRuBjXL1o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6cdc32f4-f7c8-4687-8389-fc651a292f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"Before Reshape - x_train_norm shape : {}\".format(x_train_norm.shape))\\nx_train_reshaped = x_train_norm.reshape( -1, 28, 28, 3) # 데이터 갯수에 -1을 쓰면, reshape시 자동계산됩니다.\\nprint(\"After Reshape - x_train_reshaped shape : {}\".format(x_train_reshaped.shape))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "model.compile(optimizer='adam', # 아담\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
        "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
      ],
      "metadata": {
        "id": "TpKw9D02yamm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5feb614-a12f-4ec5-b238-da5d04204aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 10s 5ms/step - loss: 1.1039 - accuracy: 0.3933\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 0.4867\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9217 - accuracy: 0.9233\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.9600\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.9733\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9900\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9800\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9867\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9967\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9967\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9967\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f92fe3cb4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "테스트\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Q1H7a-mYyd_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트용 이미지 300개를 ~/aiffel/aiffel/rock_scissor_paper/test 디렉토리에 모두 넣어,\n",
        "\n",
        "0 ~ 99 까지, 100 ~ 199까지, 200 ~ 299까지,  가위, 바위, 보 순서로 label을 설정했었으나,\n",
        "\n",
        "파일명 순으로 가져오지 못하는 것을 발견하여,\n",
        "\n",
        "test 디렉토리 밑에, scissor, rock, paper 각각 디렉토리를 만들어 가져오도록 함.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xt2weqV7yixv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "테스트용 데이터 28x28로 리사이즈"
      ],
      "metadata": {
        "id": "mFr39iTB0-TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서 resize\n",
        "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
        "'''\n",
        "image_dir_path = join(DIR_img, 'test')\n",
        "resize_images(image_dir_path)\n",
        "print(\"test 이미지 resize 완료!\")\n",
        "'''\n",
        "# 1개의 디렉토리에서 화일명 순서로 label을 식별 불가했음."
      ],
      "metadata": {
        "id": "2oUxRW3SzuEq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8ee078d-3d5f-45be-fd8d-797e3ecb4fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimage_dir_path = join(DIR_img, \\'test\\')\\nresize_images(image_dir_path)\\nprint(\"test 이미지 resize 완료!\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import join\n",
        "DIR_img = '/content/drive/MyDrive/_aiffel/aiffel/rock_scissor_paper'\n",
        "\n",
        "# TEST용 데이터 리사이즈\n",
        "image_dir_path = join(DIR_img, 'test/scissor')\n",
        "resize_images(image_dir_path)\n",
        "print(\"Test용 가위 이미지 resize 완료!\")\n",
        "\n",
        "image_dir_path = join(DIR_img, 'test/rock')\n",
        "resize_images(image_dir_path)\n",
        "print(\"Test용 바위 이미지 resize 완료!\")\n",
        "\n",
        "image_dir_path = join(DIR_img, 'test/paper')\n",
        "resize_images(image_dir_path)\n",
        "print(\"Test용 보 이미지 resize 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJRVuJkfSJpd",
        "outputId": "0651aada-ddd2-433f-87c0-62fbb051cf89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100  images to be resized.\n",
            "100  images resized.\n",
            "Test용 가위 이미지 resize 완료!\n",
            "100  images to be resized.\n",
            "100  images resized.\n",
            "Test용 바위 이미지 resize 완료!\n",
            "100  images to be resized.\n",
            "100  images resized.\n",
            "Test용 보 이미지 resize 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "테스트용 데이터 로딩"
      ],
      "metadata": {
        "id": "QcXemcDT1E-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터용 load 함수\n",
        "'''\n",
        "def load_test_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
        "    # 가위 : 0, 바위 : 1, 보 : 2\n",
        "    img_size=28\n",
        "    color=3\n",
        "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'/test/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "\n",
        "        if(idx <= 100):\n",
        "            labels[idx]=0   # 가위 : 0\n",
        "        if(idx > 100 and idx <= 200):\n",
        "            labels[idx]=1   # 바위 : 1\n",
        "        if(idx > 200 and idx <= 300):\n",
        "            labels[idx]=2   # 보 : 2\n",
        "\n",
        "        idx=idx+1\n",
        "        \n",
        "    print(\"테스트 데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
        "    return imgs, labels\n",
        "'''"
      ],
      "metadata": {
        "id": "4my3fXnEyfky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "ce145a3d-47c4-4e47-ad7e-3fa2b5fb9425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef load_test_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\\n    # 가위 : 0, 바위 : 1, 보 : 2\\n    img_size=28\\n    color=3\\n    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\\n    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\\n    labels=np.zeros(number_of_data,dtype=np.int32)\\n\\n    idx=0\\n    for file in glob.iglob(img_path+\\'/test/*.jpg\\'):\\n        img = np.array(Image.open(file),dtype=np.int32)\\n        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\\n\\n        if(idx <= 100):\\n            labels[idx]=0   # 가위 : 0\\n        if(idx > 100 and idx <= 200):\\n            labels[idx]=1   # 바위 : 1\\n        if(idx > 200 and idx <= 300):\\n            labels[idx]=2   # 보 : 2\\n\\n        idx=idx+1\\n        \\n    print(\"테스트 데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\\n    return imgs, labels\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터용 load 함수\n",
        "# scissor, rock, paper 디렉토리의 jpg 이미지들을, 편리하게 읽어들이는 함수\n",
        "def load_test_data(img_path, number_of_data=300):    # 가위바위보 이미지 갯수 총합 300장\n",
        "\n",
        "    # 가위:0 | 바위:1 | 보:2\n",
        "    img_size = 28\n",
        "    color = 3\n",
        "\n",
        "    # 이미지 데이터와 라벨(가위:0 | 바위:1 | 보:2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
        "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
        "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
        "\n",
        "    idx = 0\n",
        "    for file in glob.iglob(img_path + '/test/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img    # 데이터 영역에 이미지 행력을 복사\n",
        "        labels[idx]=0   # 가위 : 0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path + '/test/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=1   # 바위 : 1\n",
        "        idx=idx+1  \n",
        "    \n",
        "    for file in glob.iglob(img_path + '/test/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=2   # 보 : 2\n",
        "        idx=idx+1\n",
        "        \n",
        "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
        "    return imgs, labels"
      ],
      "metadata": {
        "id": "ZewW5FudTmOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트용 데이터 load\n",
        "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
        "(x_test, y_test) = load_test_data(DIR_img)"
      ],
      "metadata": {
        "id": "kLqhjI460L34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe37fb7-5372-47b1-c4fa-4c62aab1ef07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습데이터(x_train)의 이미지 개수는 300 입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트용 데이터 정규화\n",
        "x_test_norm = x_test / 255.0   # 입력은 0~1 사이의 값으로 정규화\n",
        "\n",
        "print(\"x_test shape: {}\".format(x_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "metadata": {
        "id": "AXRJ-4a31sbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8333e81d-434e-4ecf-ba14-8a4eabd70ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test shape: (300, 28, 28, 3)\n",
            "y_test shape: (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트용 데이터 Reshape\n",
        "'''\n",
        "print(\"Before Reshape - x_test_norm shape  : {}\".format(x_test_norm.shape))\n",
        "x_test_reshaped  = x_test_norm.reshape ( -1, 28, 28, 3)\n",
        "print(\"After Reshape - x_test_reshaped shape  : {}\".format(x_test_reshaped.shape))\n",
        "'''"
      ],
      "metadata": {
        "id": "VvyA0Wtx2BEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ef5e1974-7f95-4373-d016-100bdd38258e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"Before Reshape - x_test_norm shape  : {}\".format(x_test_norm.shape))\\nx_test_reshaped  = x_test_norm.reshape ( -1, 28, 28, 3)\\nprint(\"After Reshape - x_test_reshaped shape  : {}\".format(x_test_reshaped.shape))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.evaluate\n",
        "#test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
        "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
        "print(\"test_loss    : {}\".format(test_loss))\n",
        "print(\"test_accuracy: {}\".format(test_accuracy))"
      ],
      "metadata": {
        "id": "qqGdwMat2LL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ba6bde-6bef-4d92-d66f-65e15244b850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 - 0s - loss: 9.3071 - accuracy: 0.3333 - 145ms/epoch - 14ms/step\n",
            "test_loss    : 9.307053565979004\n",
            "test_accuracy: 0.3333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 회고\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "t0d8524xAZyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 노드에서 느낀 점은,\n",
        "\n",
        "\n",
        "훈련용 데이터를 대상으로 하는 accuracy 에서는,\n",
        "\n",
        "훈련용 데이터 내에서 맞고 틀린 것만으로 따지기 때문에,\n",
        "\n",
        "Hyperparameters를 조정하여, accuracy를 아무리 100%에 가깝게 만들어도.......\n",
        "\n",
        "\n",
        "새로운 테스트 데이터에서는 무용지물이 될 수 있다는 사실을 확실히 체감하게 되었습니다.\n",
        "\n",
        "또한, 훈련량을 늘리면 훈련용 데이터에서의 accuracy는 소폭이라도 증가하게 되지만,\n",
        "\n",
        "테스트 데이터에서도 accuracy가 증가하는 것이 아니라,\n",
        "\n",
        "오히려 감소할 수도 있음을 확인할 수 있었습니다."
      ],
      "metadata": {
        "id": "Kkft93ZYAgSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습용 데이터의 중요성에 대하여서도 생각해 보는 기회가 되었습니다.\n",
        "\n",
        "다양한 환경을 고려한 충분한 학습용 데이터가 필요하며,\n",
        "\n",
        "학습용 데이터에서 특징을 추출할 수 있어야만,\n",
        "\n",
        "테스트 데이터에서 해당 특징으로 식별이 용이하지 않을까 생각해 보았습니다.\n",
        "\n",
        "단일 조건에서의 데이터로 학습했을 경우,\n",
        "\n",
        "별개의 다양한 환경의 테스트 데이터가 들어왔을 경우, 이를 식별할 수 있을까 생각해 보았습니다."
      ],
      "metadata": {
        "id": "pDtKDxLJeGMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensorflow 에서 Keras 라는 것을 가져와서,\n",
        "\n",
        "Sequential 모델을 사용하는 것을 보게 되었습니다.\n",
        "\n",
        "Sequential 모델에 단지 add 하면서 layer를 추가하는 모습을 보며,\n",
        "\n",
        "이렇게 간단하게 몇 줄로 레이어가 추가되는 것이 신기하게 느껴졌습니다.\n",
        "\n",
        "다만, 아직도 어떠한 레이어들이 있고, 어떤 기능을 하는지 정확히 알지 못하며,\n",
        "\n",
        "궁극적으로는 높은 추상화를 이룰 수 있어야만,\n",
        "\n",
        "다양한 환경과 노이즈에서도 대상을 정확히 식별할 수 있지 않을까,\n",
        "\n",
        "어렴풋이 생각해 보는 시간이 되었습니다."
      ],
      "metadata": {
        "id": "pquDabtIZLwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S5i4Kjh3spHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}